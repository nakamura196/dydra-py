{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dydra API client\n",
    "\n",
    "> Tools to interact with the Dydra API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import requests\n",
    "import rdflib\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import tempfile\n",
    "from rdflib import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DydraClient():    \n",
    "    \"\"\"\n",
    "    A client for interacting with a Dydra SPARQL endpoint.\n",
    "\n",
    "    Attributes:\n",
    "        endpoint (str): The SPARQL endpoint URL.\n",
    "        api_key (str): The API key for authorization.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def load_env(path):\n",
    "        \"\"\"\n",
    "        Loads environment variables from a specified .env file.\n",
    "        \n",
    "        Args:\n",
    "            path (str): Path to the .env file.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Contains the endpoint and API key as strings.\n",
    "        \"\"\"\n",
    "\n",
    "        load_dotenv(path)\n",
    "\n",
    "        return os.getenv(\"DYDRA_ENDPOINT\"), os.getenv(\"DYDRA_API_KEY\")\n",
    "\n",
    "\n",
    "    def __init__(self, endpoint, api_key):\n",
    "        \"\"\"\n",
    "        Initializes the DydraClient with the given endpoint and API key.\n",
    "        \n",
    "        Args:\n",
    "            endpoint (str): The SPARQL endpoint URL.\n",
    "            api_key (str): The API key for authorization.\n",
    "        \"\"\"\n",
    "        self.endpoint = endpoint\n",
    "        self.api_key = api_key\n",
    "\n",
    "    def import_by_file(self, file_path, format, graph_uri=None, verbose=False):\n",
    "        \"\"\"\n",
    "        Imports RDF data from a file into the Dydra store.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): The path to the RDF file to import.\n",
    "            format (str): The format of the RDF file (e.g., 'xml', 'nt').\n",
    "            graph_uri (str, optional): URI of the graph where data will be inserted. Defaults to None.\n",
    "        \"\"\"\n",
    "\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/sparql-update\"\n",
    "        }\n",
    "\n",
    "        files = self._chunk_rdf_file(file_path, format=format)\n",
    "\n",
    "        print(\"Number of chunks: \", len(files))\n",
    "\n",
    "        for file in tqdm(files):\n",
    "\n",
    "            # RDFファイルの読み込み\n",
    "            graph = rdflib.Graph()\n",
    "            graph.parse(file, format=format)  # フォーマットはファイルに応じて変更\n",
    "\n",
    "            nt_data = graph.serialize(format='nt')\n",
    "\n",
    "            if graph_uri is None:\n",
    "                query = f\"\"\"\n",
    "                INSERT DATA {{\n",
    "                {nt_data}\n",
    "                }}\n",
    "                \"\"\"\n",
    "\n",
    "            else:\n",
    "                query = f\"\"\"\n",
    "                INSERT DATA {{\n",
    "                GRAPH <{graph_uri}> {{\n",
    "                    {nt_data}\n",
    "                }}\n",
    "                }}\n",
    "                \"\"\"\n",
    "\n",
    "            if verbose:\n",
    "                print(query)\n",
    "\n",
    "            response = requests.post(self.endpoint, data=query, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                print(\"Data successfully inserted.\")\n",
    "            else:\n",
    "                print(f\"Error: {response.status_code} {response.text}\")\n",
    "\n",
    "    def delete_by_file(self, file_path, format, graph_uri=None, verbose=False):\n",
    "        \"\"\"\n",
    "        Deletes RDF data from a file in the Dydra store.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): The path to the RDF file to delete.\n",
    "            format (str): The format of the RDF file (e.g., 'xml', 'nt').\n",
    "            graph_uri (str, optional): URI of the graph where data will be deleted. Defaults to None.\n",
    "        \"\"\"\n",
    "\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/sparql-update\"\n",
    "        }\n",
    "\n",
    "        files = self._chunk_rdf_file(file_path, format=format)\n",
    "\n",
    "        print(\"Number of chunks: \", len(files))\n",
    "\n",
    "        for file in tqdm(files):\n",
    "\n",
    "            # RDFファイルの読み込み\n",
    "            graph = rdflib.Graph()\n",
    "            graph.parse(file, format=format)  # フォーマットはファイルに応じて変更\n",
    "\n",
    "            nt_data = graph.serialize(format='nt')\n",
    "\n",
    "            if graph_uri is None:\n",
    "                query = f\"\"\"\n",
    "                DELETE DATA {{\n",
    "                {nt_data}\n",
    "                }}\n",
    "                \"\"\"\n",
    "\n",
    "            else:\n",
    "\n",
    "                query = f\"\"\"\n",
    "                DELETE DATA {{\n",
    "                GRAPH <{graph_uri}> {{\n",
    "                    {nt_data}\n",
    "                }}\n",
    "                }}\n",
    "                \"\"\"\n",
    "\n",
    "            if verbose:\n",
    "                print(query)\n",
    "\n",
    "            response = requests.post(self.endpoint, data=query, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                print(\"Data successfully deleted.\")\n",
    "            else:\n",
    "                print(f\"Error: {response.status_code} {response.text}\")\n",
    "\n",
    "    def query(self, query):\n",
    "        \"\"\"\n",
    "        Executes a SPARQL query against the endpoint and returns the results.\n",
    "\n",
    "        Args:\n",
    "            query (str): The SPARQL query to execute.\n",
    "\n",
    "        Returns:\n",
    "            dict: The query results in JSON format.\n",
    "        \"\"\"\n",
    "\n",
    "        # SPARQLエンドポイントの設定\n",
    "        sparql = SPARQLWrapper(self.endpoint)\n",
    "\n",
    "        # クエリの設定\n",
    "        sparql.setQuery(query)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "\n",
    "        results = sparql.query().convert()\n",
    "\n",
    "        return results\n",
    "    \n",
    "    def clear(self, graph_uri=None):\n",
    "        \"\"\"\n",
    "        Clears all data from the default or specified graph.\n",
    "\n",
    "        Args:\n",
    "            graph_uri (str, optional): URI of the graph to clear. Defaults to None.\n",
    "        \"\"\"\n",
    "\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/sparql-update\"\n",
    "        }\n",
    "\n",
    "        if graph_uri is None:\n",
    "            query = \"\"\"\n",
    "            DELETE {\n",
    "            ?s ?p ?o\n",
    "            }\n",
    "            WHERE {\n",
    "            ?s ?p ?o\n",
    "            }\n",
    "            \"\"\"\n",
    "\n",
    "        else:\n",
    "            query = f\"\"\"\n",
    "            DELETE {{\n",
    "            GRAPH <{graph_uri}> {{\n",
    "                ?s ?p ?o\n",
    "            }}\n",
    "            }}\n",
    "            WHERE {{\n",
    "            GRAPH <{graph_uri}> {{\n",
    "                ?s ?p ?o\n",
    "            }}\n",
    "            }}\n",
    "            \"\"\"\n",
    "\n",
    "        response = requests.post(self.endpoint, data=query, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            print(\"Data successfully cleared.\")\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} {response.text}\")\n",
    "\n",
    "    def _serialize_chunk(self, graph, index, format='turtle'):\n",
    "        output_dir = self.output_dir\n",
    "        \"\"\"チャンクをファイルにシリアライズする補助関数\"\"\"\n",
    "        filename = f\"{output_dir}/output_chunk_{index}.{format}\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        graph.serialize(filename, format=format)\n",
    "        # print(f\"Saved {filename}, size: {os.path.getsize(filename)} bytes\")\n",
    "\n",
    "        return filename\n",
    "\n",
    "    def _clear_output_dir(self, output_dir):\n",
    "        shutil.rmtree(output_dir, ignore_errors=True)\n",
    "\n",
    "    def _chunk_rdf_file(self, input_file, output_dir=None, chunk_size=500*1024, format='turtle'):\n",
    "        if output_dir is None:\n",
    "            output_dir = tempfile.mkdtemp()\n",
    "\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "        self._clear_output_dir(output_dir)\n",
    "\n",
    "        \"\"\"RDF ファイルを指定されたサイズのチャンクに分割する\"\"\"\n",
    "        g = Graph()\n",
    "        g.parse(input_file, format=format)\n",
    "\n",
    "        current_chunk = Graph()\n",
    "        current_size = 0\n",
    "        chunk_index = 1\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        files = []\n",
    "\n",
    "        print(\"Triple count: \", len(g))\n",
    "\n",
    "        for s, p, o in tqdm(g):\n",
    "            count += 1\n",
    "\n",
    "            # 一時的なグラフにトリプルを追加\n",
    "            current_chunk.add((s, p, o))\n",
    "\n",
    "            if count % 1000 == 0:\n",
    "\n",
    "                # シリアライズしてサイズを確認\n",
    "                temp_serialized = current_chunk.serialize(format=format)\n",
    "                temp_size = len(temp_serialized)\n",
    "\n",
    "                # 現在のチャンクサイズが設定値を超えたらシリアライズしてファイルに保存\n",
    "                if temp_size >= chunk_size:\n",
    "                    path = self._serialize_chunk(current_chunk, chunk_index, format=format)\n",
    "                    files.append(path)\n",
    "                    current_chunk = Graph()  # 新しいグラフを開始\n",
    "                    chunk_index += 1\n",
    "\n",
    "        # 最後のチャンクを保存\n",
    "        if len(current_chunk) > 0:\n",
    "            path = self._serialize_chunk(current_chunk, chunk_index, format=format)\n",
    "            files.append(path)\n",
    "\n",
    "        return files\n",
    "\n",
    "    def delete_by_subjects(self, subject_uris, graph_uri=None, verbose=False):\n",
    "        \"\"\"\n",
    "        Deletes RDF data from the Dydra store based on a list of subject URIs.\n",
    "\n",
    "        Args:\n",
    "            subject_uris (list): List of subject URIs to delete.\n",
    "        \"\"\"\n",
    "\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/sparql-update\"\n",
    "        }\n",
    "\n",
    "        # Function to chunk URIs into batches\n",
    "        def _chunked_uris(uris, chunk_size):\n",
    "            for i in range(0, len(uris), chunk_size):\n",
    "                yield uris[i:i + chunk_size]\n",
    "\n",
    "        # Iterate over URI chunks\n",
    "        for uri_chunk in tqdm(_chunked_uris(subject_uris, 100)):\n",
    "            if graph_uri is None:\n",
    "                query = f\"\"\"\n",
    "                DELETE {{\n",
    "                    ?uri ?p ?o\n",
    "                }}\n",
    "                WHERE {{\n",
    "                    VALUES ?uri {{ {' '.join(f'<{uri}>' for uri in uri_chunk)} }}\n",
    "                    ?uri ?p ?o\n",
    "                }}\n",
    "                \"\"\"\n",
    "            else:\n",
    "                query = f\"\"\"\n",
    "                DELETE {{\n",
    "                    GRAPH <{graph_uri}> {{\n",
    "                        ?uri ?p ?o\n",
    "                    }}\n",
    "                }}\n",
    "                WHERE {{\n",
    "                    GRAPH <{graph_uri}> {{\n",
    "                        VALUES ?uri {{ {' '.join(f'<{uri}>' for uri in uri_chunk)} }}\n",
    "                        ?uri ?p ?o\n",
    "                    }}\n",
    "                }}\n",
    "                \"\"\"\n",
    "\n",
    "            if verbose:\n",
    "                # print(query)\n",
    "                pass\n",
    "\n",
    "            response = requests.post(self.endpoint, data=query, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                if verbose:\n",
    "                    print(f\"Data for URIs successfully deleted.\")\n",
    "            else:\n",
    "                print(f\"Error: {response.status_code} {response.text}\")\n",
    "\n",
    "        '''\n",
    "        for uri in tqdm(subject_uris):\n",
    "\n",
    "            if graph_uri is None:\n",
    "\n",
    "                query = f\"\"\"\n",
    "            DELETE {{\n",
    "            <{uri}> ?p ?o\n",
    "            }}\n",
    "            WHERE {{\n",
    "            <{uri}> ?p ?o\n",
    "            }}\n",
    "            \"\"\"\n",
    "                \n",
    "            else:\n",
    "                query = f\"\"\"\n",
    "            DELETE {{\n",
    "            GRAPH <{graph_uri}> {{\n",
    "                <{uri}> ?p ?o\n",
    "            }}\n",
    "            }}\n",
    "            WHERE {{\n",
    "            GRAPH <{graph_uri}> {{\n",
    "                <{uri}> ?p ?o\n",
    "            }}\n",
    "            }}\n",
    "            \"\"\"\n",
    "                \n",
    "            if verbose:\n",
    "                print(query)\n",
    "\n",
    "            response = requests.post(self.endpoint, data=query, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                # print(f\"Data for {uri} successfully deleted.\")\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"Error: {response.status_code} {response.text}\")\n",
    "        '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/nakamura196/dydra-py/blob/main/dydra_py/core.py#L29){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DydraClient.import_by_file\n",
       "\n",
       ">      DydraClient.import_by_file (file_path, format, graph_uri=None,\n",
       ">                                  verbose=False)\n",
       "\n",
       "*Imports RDF data from a file into the Dydra store.\n",
       "\n",
       "Args:\n",
       "    file_path (str): The path to the RDF file to import.\n",
       "    format (str): The format of the RDF file (e.g., 'xml', 'nt').\n",
       "    graph_uri (str, optional): URI of the graph where data will be inserted. Defaults to None.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/nakamura196/dydra-py/blob/main/dydra_py/core.py#L29){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DydraClient.import_by_file\n",
       "\n",
       ">      DydraClient.import_by_file (file_path, format, graph_uri=None,\n",
       ">                                  verbose=False)\n",
       "\n",
       "*Imports RDF data from a file into the Dydra store.\n",
       "\n",
       "Args:\n",
       "    file_path (str): The path to the RDF file to import.\n",
       "    format (str): The format of the RDF file (e.g., 'xml', 'nt').\n",
       "    graph_uri (str, optional): URI of the graph where data will be inserted. Defaults to None.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DydraClient.import_by_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/nakamura196/dydra-py/blob/main/dydra_py/api.py#L107){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DydraClient.delete_by_file\n",
       "\n",
       ">      DydraClient.delete_by_file (file_path, format, graph_uri=None,\n",
       ">                                  verbose=False)\n",
       "\n",
       "*Deletes RDF data from a file in the Dydra store.\n",
       "\n",
       "Args:\n",
       "    file_path (str): The path to the RDF file to delete.\n",
       "    format (str): The format of the RDF file (e.g., 'xml', 'nt').\n",
       "    graph_uri (str, optional): URI of the graph where data will be deleted. Defaults to None.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/nakamura196/dydra-py/blob/main/dydra_py/api.py#L107){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DydraClient.delete_by_file\n",
       "\n",
       ">      DydraClient.delete_by_file (file_path, format, graph_uri=None,\n",
       ">                                  verbose=False)\n",
       "\n",
       "*Deletes RDF data from a file in the Dydra store.\n",
       "\n",
       "Args:\n",
       "    file_path (str): The path to the RDF file to delete.\n",
       "    format (str): The format of the RDF file (e.g., 'xml', 'nt').\n",
       "    graph_uri (str, optional): URI of the graph where data will be deleted. Defaults to None.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DydraClient.delete_by_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/nakamura196/dydra-py/blob/main/dydra_py/api.py#L287){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DydraClient.delete_by_subjects\n",
       "\n",
       ">      DydraClient.delete_by_subjects (subject_uris, graph_uri=None,\n",
       ">                                      verbose=False)\n",
       "\n",
       "*Deletes RDF data from the Dydra store based on a list of subject URIs.\n",
       "\n",
       "Args:\n",
       "    subject_uris (list): List of subject URIs to delete.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/nakamura196/dydra-py/blob/main/dydra_py/api.py#L287){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DydraClient.delete_by_subjects\n",
       "\n",
       ">      DydraClient.delete_by_subjects (subject_uris, graph_uri=None,\n",
       ">                                      verbose=False)\n",
       "\n",
       "*Deletes RDF data from the Dydra store based on a list of subject URIs.\n",
       "\n",
       "Args:\n",
       "    subject_uris (list): List of subject URIs to delete.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DydraClient.delete_by_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/nakamura196/dydra-py/blob/main/dydra_py/core.py#L66){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DydraClient.query\n",
       "\n",
       ">      DydraClient.query (query)\n",
       "\n",
       "*Executes a SPARQL query against the endpoint and returns the results.\n",
       "\n",
       "Args:\n",
       "    query (str): The SPARQL query to execute.\n",
       "\n",
       "Returns:\n",
       "    dict: The query results in JSON format.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/nakamura196/dydra-py/blob/main/dydra_py/core.py#L66){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DydraClient.query\n",
       "\n",
       ">      DydraClient.query (query)\n",
       "\n",
       "*Executes a SPARQL query against the endpoint and returns the results.\n",
       "\n",
       "Args:\n",
       "    query (str): The SPARQL query to execute.\n",
       "\n",
       "Returns:\n",
       "    dict: The query results in JSON format.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DydraClient.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/nakamura196/dydra-py/blob/main/dydra_py/core.py#L82){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DydraClient.clear\n",
       "\n",
       ">      DydraClient.clear (graph_uri=None)\n",
       "\n",
       "*Clears all data from the default or specified graph.\n",
       "\n",
       "Args:\n",
       "    graph_uri (str, optional): URI of the graph to clear. Defaults to None.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/nakamura196/dydra-py/blob/main/dydra_py/core.py#L82){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DydraClient.clear\n",
       "\n",
       ">      DydraClient.clear (graph_uri=None)\n",
       "\n",
       "*Clears all data from the default or specified graph.\n",
       "\n",
       "Args:\n",
       "    graph_uri (str, optional): URI of the graph to clear. Defaults to None.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DydraClient.clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
